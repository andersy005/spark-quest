{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](http://spark.apache.org/images/spark-logo.png) ![](https://upload.wikimedia.org/wikipedia/commons/f/f8/Python_logo_and_wordmark.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(10000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosaving every 10 seconds\n"
     ]
    }
   ],
   "source": [
    "%autosave 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLlib: Classification with Decision Trees\n",
    "\n",
    "In this notebook we will use Spark's machine learning library MLlib to build a **Decision Tree classifier** for network attack detection. We will use the complete [KDD Cup 1999 datasets](http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html) in order to test Spark capabilities with large datasets.\n",
    "\n",
    "Decision trees are a popular machine learning tool in part because:\n",
    "- they are easy to interpret, \n",
    "- handle categorical features, \n",
    "- extend to the multiclass classification setting, \n",
    "- do not require feature scaling, and \n",
    "- are able to capture non-linearities and feature interactions. \n",
    "\n",
    "In this notebook, we will first train a classification tree including every single predictor. Then we will use our results to perform model selection. Once we find out the most important ones (the main splits in the tree) we will build a minimal tree using just three of them (the first two levels of the tree in order to compare performance and accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data and creating the RDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib\n",
    "f = urllib.urlretrieve (\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup.data.gz\", \"kddcup.data.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size is 4898431\n"
     ]
    }
   ],
   "source": [
    "data_file = \"./kddcup.data.gz\"\n",
    "raw_data = sc.textFile(data_file)\n",
    "\n",
    "print \"Train data size is {}\".format(raw_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test dataset\n",
    "ft = urllib.urlretrieve(\"http://kdd.ics.uci.edu/databases/kddcup99/corrected.gz\", \"corrected.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data size is 311029\n"
     ]
    }
   ],
   "source": [
    "test_data_file = \"./corrected.gz\"\n",
    "test_raw_data = sc.textFile(test_data_file)\n",
    "\n",
    "print \"Test data size is {}\".format(test_raw_data.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting network attacks using Decision Trees\n",
    "In this section we will train a *classification tree* that, as we did with *logistic regression*, will predict if a network interaction is either normal or attack.\n",
    "\n",
    "Training a classification tree using **MLlib** requires some parameters:\n",
    "\n",
    "- Training data\n",
    "- Num classes\n",
    "- Categorical features info: a map from column to categorical variables arity. This is optional, although it should increase model accuracy. However it requires that we know the levels in our categorical variables in advance. second we need to parse our data to convert labels to integer values within the arity range.\n",
    "- Impurity metric\n",
    "- Tree maximum depth\n",
    "- And tree maximum number of bins\n",
    "\n",
    "\n",
    "# Training Data Preprocessing\n",
    "\n",
    "In order to benefits from trees ability to seamlessly work with categorical variables, we need to convert them to numerical factors. But first we need to obtain all the possible levels. We will use **set transformations** on csv parsed RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.regression import LabeledPoint\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_data = raw_data.map(lambda x: x.split(\",\"))\n",
    "test_csv_data = test_raw_data.map(lambda x: x.split(\",\"))\n",
    "\n",
    "protocols = csv_data.map(lambda x: x[1]).distinct().collect()\n",
    "services = csv_data.map(lambda x: x[2]).distinct().collect()\n",
    "flags = csv_data.map(lambda x: x[3]).distinct().collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this Python list in our ```create_labeled_point``` function. If a factor level is not in the training data, we assign an especial level. \n",
    "\n",
    "Note: We cannot use testing data for training our model, not even the factor levels. The testing data represents the unknown to us in a real case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_labeled_point(line_split):\n",
    "    # leave out =[41]\n",
    "    clean_line_split = line_split[0:41]\n",
    "    # convert protocol to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[1] = protocols.index(clean_line_split[1])\n",
    "        \n",
    "    except:\n",
    "        clean_line_split[1] = len(protocols)\n",
    " \n",
    "    # convert service to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[2] = services.index(clean_line_split[2])\n",
    "        \n",
    "    except:\n",
    "        clean_line_split[2] = len(services)\n",
    "\n",
    "    # convert flag to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[3] = flags.index(clean_line_split[3])\n",
    "        \n",
    "    except:\n",
    "        clean_line_split[3] = len(flags)\n",
    "        \n",
    "    attack = 1.0\n",
    "    if line_split[41] ==\"normal.\":\n",
    "        attack = 0.0\n",
    "        \n",
    "    return LabeledPoint(attack, np.array([float(x) for x in clean_line_split]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data = csv_data.map(create_labeled_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [0.0,2.0,58.0,10.0,215.0,45076.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0]),\n",
       " LabeledPoint(0.0, [0.0,2.0,58.0,10.0,162.0,4528.0,0.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,2.0,2.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,1.0,1.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data Preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = test_csv_data.map(create_labeled_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [0.0,0.0,5.0,10.0,105.0,146.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,255.0,254.0,1.0,0.01,0.0,0.0,0.0,0.0,0.0,0.0])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training a classifier\n",
    "\n",
    "We are now ready to train our classification tree. We will keep the maxDepth value small. This will lead to smaller accuracy, but we will obtain less splits so later on we can better interpret the tree. In a production system we will try to increase this value in order to find a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 352.452 seconds\n"
     ]
    }
   ],
   "source": [
    "from pyspark.mllib.tree import DecisionTree, DecisionTreeModel\n",
    "from time import time\n",
    "\n",
    "# Build the model\n",
    "t0 = time()\n",
    "tree_model = DecisionTree.trainClassifier(training_data, numClasses=2,\n",
    "                                          categoricalFeaturesInfo={1: len(protocols),\n",
    "                                                                   2: len(services),\n",
    "                                                                   3: len(flags)},\n",
    "                                          impurity='gini', maxDepth=8, maxBins=200)\n",
    "tt = time() - t0\n",
    "\n",
    "print \"Classifier trained in {} seconds\".format(round(tt,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating the model on new data\n",
    "In order to measure the classification error on our test data, we use map on the ```test_data``` RDD and the model to predict each test point class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = tree_model.predict(test_data.map(lambda p: p.features))\n",
    "labels_and_preds = test_data.map(lambda p: p.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification results are returned in pars, with the actual test label and the predicted one. This is used to calculate the classification error by using ```filter``` and ```count``` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 23.542 seconds. Test accuracy is 0.9215\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "test_accuracy = labels_and_preds.filter(\n",
    "             lambda (v, p): v==p).count() / float(test_data.count())\n",
    "tt = time() - t0\n",
    "\n",
    "print \"Prediction made in {} seconds. Test accuracy is {}\".format(round(tt,3), round(test_accuracy,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpreting the model\n",
    "\n",
    "Understanding our tree splits is a great exercise in order to explaiin our classification labels in terms of predictors and the values they take. Using the ```toDebugString``` method in our tree model we can obtain a lot of information regarding splits, nodes, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learned classification tree model:\n",
      "DecisionTreeModel classifier of depth 8 with 157 nodes\n",
      "  If (feature 22 <= 43.0)\n",
      "   If (feature 3 in {2.0,3.0,4.0,7.0,9.0,10.0})\n",
      "    If (feature 36 <= 0.45)\n",
      "     If (feature 12 <= 0.0)\n",
      "      If (feature 34 <= 0.91)\n",
      "       If (feature 7 <= 0.0)\n",
      "        If (feature 36 <= 0.24)\n",
      "         If (feature 28 <= 0.19)\n",
      "          Predict: 0.0\n",
      "         Else (feature 28 > 0.19)\n",
      "          Predict: 0.0\n",
      "        Else (feature 36 > 0.24)\n",
      "         If (feature 2 in {0.0,3.0,15.0,18.0,27.0,32.0,36.0,42.0,58.0,67.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 2 not in {0.0,3.0,15.0,18.0,27.0,32.0,36.0,42.0,58.0,67.0})\n",
      "          Predict: 1.0\n",
      "       Else (feature 7 > 0.0)\n",
      "        Predict: 1.0\n",
      "      Else (feature 34 > 0.91)\n",
      "       If (feature 4 <= 1.0)\n",
      "        If (feature 39 <= 0.5)\n",
      "         If (feature 0 <= 0.0)\n",
      "          Predict: 0.0\n",
      "         Else (feature 0 > 0.0)\n",
      "          Predict: 1.0\n",
      "        Else (feature 39 > 0.5)\n",
      "         Predict: 1.0\n",
      "       Else (feature 4 > 1.0)\n",
      "        If (feature 2 in {0.0,3.0,5.0,8.0,12.0,15.0,18.0,26.0,27.0,36.0,42.0,50.0,58.0,67.0,68.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 2 not in {0.0,3.0,5.0,8.0,12.0,15.0,18.0,26.0,27.0,36.0,42.0,50.0,58.0,67.0,68.0})\n",
      "         If (feature 31 <= 5.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 31 > 5.0)\n",
      "          Predict: 0.0\n",
      "     Else (feature 12 > 0.0)\n",
      "      If (feature 33 <= 0.94)\n",
      "       If (feature 5 <= 35.0)\n",
      "        If (feature 31 <= 7.0)\n",
      "         Predict: 1.0\n",
      "        Else (feature 31 > 7.0)\n",
      "         Predict: 0.0\n",
      "       Else (feature 5 > 35.0)\n",
      "        If (feature 2 in {3.0,12.0,15.0,42.0,58.0,66.0,67.0})\n",
      "         If (feature 8 <= 0.0)\n",
      "          Predict: 0.0\n",
      "         Else (feature 8 > 0.0)\n",
      "          Predict: 0.0\n",
      "        Else (feature 2 not in {3.0,12.0,15.0,42.0,58.0,66.0,67.0})\n",
      "         Predict: 1.0\n",
      "      Else (feature 33 > 0.94)\n",
      "       If (feature 4 <= 1119.0)\n",
      "        If (feature 16 <= 1.0)\n",
      "         If (feature 2 in {42.0,58.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 2 not in {42.0,58.0})\n",
      "          Predict: 1.0\n",
      "        Else (feature 16 > 1.0)\n",
      "         Predict: 1.0\n",
      "       Else (feature 4 > 1119.0)\n",
      "        If (feature 0 <= 735.0)\n",
      "         Predict: 1.0\n",
      "        Else (feature 0 > 735.0)\n",
      "         Predict: 0.0\n",
      "    Else (feature 36 > 0.45)\n",
      "     If (feature 2 in {0.0,3.0,15.0,26.0,27.0,36.0,42.0,58.0,67.0})\n",
      "      If (feature 34 <= 0.86)\n",
      "       If (feature 9 <= 2.0)\n",
      "        If (feature 10 <= 1.0)\n",
      "         If (feature 28 <= 0.25)\n",
      "          Predict: 0.0\n",
      "         Else (feature 28 > 0.25)\n",
      "          Predict: 0.0\n",
      "        Else (feature 10 > 1.0)\n",
      "         If (feature 0 <= 23.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 0 > 23.0)\n",
      "          Predict: 0.0\n",
      "       Else (feature 9 > 2.0)\n",
      "        If (feature 4 <= 195.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 4 > 195.0)\n",
      "         Predict: 1.0\n",
      "      Else (feature 34 > 0.86)\n",
      "       If (feature 33 <= 0.25)\n",
      "        Predict: 1.0\n",
      "       Else (feature 33 > 0.25)\n",
      "        Predict: 0.0\n",
      "     Else (feature 2 not in {0.0,3.0,15.0,26.0,27.0,36.0,42.0,58.0,67.0})\n",
      "      If (feature 4 <= 18.0)\n",
      "       Predict: 1.0\n",
      "      Else (feature 4 > 18.0)\n",
      "       If (feature 4 <= 331.0)\n",
      "        Predict: 0.0\n",
      "       Else (feature 4 > 331.0)\n",
      "        If (feature 15 <= 0.0)\n",
      "         Predict: 1.0\n",
      "        Else (feature 15 > 0.0)\n",
      "         Predict: 0.0\n",
      "   Else (feature 3 not in {2.0,3.0,4.0,7.0,9.0,10.0})\n",
      "    If (feature 33 <= 0.3)\n",
      "     If (feature 5 <= 0.0)\n",
      "      If (feature 36 <= 0.15)\n",
      "       If (feature 2 in {1.0,2.0,3.0})\n",
      "        If (feature 37 <= 0.02)\n",
      "         If (feature 3 in {5.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 3 not in {5.0})\n",
      "          Predict: 1.0\n",
      "        Else (feature 37 > 0.02)\n",
      "         Predict: 1.0\n",
      "       Else (feature 2 not in {1.0,2.0,3.0})\n",
      "        If (feature 31 <= 29.0)\n",
      "         If (feature 2 in {42.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 2 not in {42.0})\n",
      "          Predict: 1.0\n",
      "        Else (feature 31 > 29.0)\n",
      "         If (feature 34 <= 0.01)\n",
      "          Predict: 1.0\n",
      "         Else (feature 34 > 0.01)\n",
      "          Predict: 1.0\n",
      "      Else (feature 36 > 0.15)\n",
      "       If (feature 34 <= 0.05)\n",
      "        Predict: 0.0\n",
      "       Else (feature 34 > 0.05)\n",
      "        If (feature 37 <= 0.02)\n",
      "         If (feature 3 in {5.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 3 not in {5.0})\n",
      "          Predict: 1.0\n",
      "        Else (feature 37 > 0.02)\n",
      "         Predict: 1.0\n",
      "     Else (feature 5 > 0.0)\n",
      "      If (feature 2 in {12.0,18.0,42.0,51.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 not in {12.0,18.0,42.0,51.0})\n",
      "       Predict: 1.0\n",
      "    Else (feature 33 > 0.3)\n",
      "     If (feature 38 <= 0.16)\n",
      "      If (feature 4 <= 3676.0)\n",
      "       If (feature 22 <= 9.0)\n",
      "        If (feature 10 <= 0.0)\n",
      "         If (feature 2 in {3.0,7.0,27.0,42.0,51.0,58.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 2 not in {3.0,7.0,27.0,42.0,51.0,58.0})\n",
      "          Predict: 1.0\n",
      "        Else (feature 10 > 0.0)\n",
      "         Predict: 1.0\n",
      "       Else (feature 22 > 9.0)\n",
      "        If (feature 2 in {58.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 2 not in {58.0})\n",
      "         Predict: 1.0\n",
      "      Else (feature 4 > 3676.0)\n",
      "       If (feature 2 in {3.0,50.0,51.0})\n",
      "        If (feature 3 in {1.0})\n",
      "         Predict: 0.0\n",
      "        Else (feature 3 not in {1.0})\n",
      "         Predict: 1.0\n",
      "       Else (feature 2 not in {3.0,50.0,51.0})\n",
      "        Predict: 1.0\n",
      "     Else (feature 38 > 0.16)\n",
      "      If (feature 40 <= 0.0)\n",
      "       If (feature 6 <= 0.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 6 > 0.0)\n",
      "        If (feature 38 <= 0.88)\n",
      "         If (feature 23 <= 1.0)\n",
      "          Predict: 0.0\n",
      "         Else (feature 23 > 1.0)\n",
      "          Predict: 1.0\n",
      "        Else (feature 38 > 0.88)\n",
      "         If (feature 2 in {27.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 2 not in {27.0})\n",
      "          Predict: 1.0\n",
      "      Else (feature 40 > 0.0)\n",
      "       Predict: 0.0\n",
      "  Else (feature 22 > 43.0)\n",
      "   If (feature 5 <= 0.0)\n",
      "    If (feature 2 in {0.0,52.0})\n",
      "     Predict: 0.0\n",
      "    Else (feature 2 not in {0.0,52.0})\n",
      "     If (feature 11 <= 0.0)\n",
      "      If (feature 1 in {0.0})\n",
      "       If (feature 4 <= 28.0)\n",
      "        Predict: 1.0\n",
      "       Else (feature 4 > 28.0)\n",
      "        Predict: 0.0\n",
      "      Else (feature 1 not in {0.0})\n",
      "       If (feature 31 <= 254.0)\n",
      "        If (feature 28 <= 0.0)\n",
      "         If (feature 2 in {58.0})\n",
      "          Predict: 0.0\n",
      "         Else (feature 2 not in {58.0})\n",
      "          Predict: 1.0\n",
      "        Else (feature 28 > 0.0)\n",
      "         Predict: 1.0\n",
      "       Else (feature 31 > 254.0)\n",
      "        If (feature 34 <= 0.08)\n",
      "         Predict: 1.0\n",
      "        Else (feature 34 > 0.08)\n",
      "         If (feature 1 in {1.0})\n",
      "          Predict: 1.0\n",
      "         Else (feature 1 not in {1.0})\n",
      "          Predict: 1.0\n",
      "     Else (feature 11 > 0.0)\n",
      "      If (feature 2 in {12.0})\n",
      "       Predict: 0.0\n",
      "      Else (feature 2 not in {12.0})\n",
      "       Predict: 1.0\n",
      "   Else (feature 5 > 0.0)\n",
      "    If (feature 29 <= 0.08)\n",
      "     If (feature 2 in {3.0,4.0,26.0,36.0,42.0,58.0,68.0})\n",
      "      If (feature 3 in {10.0})\n",
      "       If (feature 39 <= 0.99)\n",
      "        If (feature 16 <= 0.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 16 > 0.0)\n",
      "         If (feature 0 <= 127.0)\n",
      "          Predict: 1.0\n",
      "         Else (feature 0 > 127.0)\n",
      "          Predict: 0.0\n",
      "       Else (feature 39 > 0.99)\n",
      "        If (feature 0 <= 0.0)\n",
      "         Predict: 0.0\n",
      "        Else (feature 0 > 0.0)\n",
      "         Predict: 1.0\n",
      "      Else (feature 3 not in {10.0})\n",
      "       Predict: 1.0\n",
      "     Else (feature 2 not in {3.0,4.0,26.0,36.0,42.0,58.0,68.0})\n",
      "      Predict: 1.0\n",
      "    Else (feature 29 > 0.08)\n",
      "     Predict: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print \"Learned classification tree model:\"\n",
    "print tree_model.toDebugString()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, a network interaction with the following features (see description [here](http://kdd.ics.uci.edu/databases/kddcup99/task.html)) will be classified as an attack by our model:\n",
    "\n",
    "- ```count```, the number of connections to the same host as the current connection in the past two seconds, being greater than 32.\n",
    "- ```dst_bytes```, the number of data bytes from destination to source, is 0.\n",
    "- ```service``` is neither level 0 nor 52.\n",
    "- ```logged_in``` is false.\n",
    "From our services list we know that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service 0 is urp_i\n",
      "Service 52 is tftp_u\n"
     ]
    }
   ],
   "source": [
    "print \"Service 0 is {}\".format(services[0])\n",
    "print \"Service 52 is {}\".format(services[52])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we can characterise network interactions with more than 32 connections to the same server in the last 3 seconds, transferring zero bytes from destination to source, where service is neither ```urp_i``` nor ```tftp_u```, and not loggen in, as network attacks. A similar approach can be used for each tree terminal node.\n",
    "\n",
    "We can see that ```count``` is the first node split in the tree. Remember that each partition is chosen greedily by selecting the best split from a set of possible splits, in order to maximize the information gain at a tree node (see more [here](https://spark.apache.org/docs/latest/mllib-decision-tree.html#basic-algorithm)). At a second level we find variables ```flag``` (normal or error status of the connection) and ```dst_bytes``` (the number of data bytes from destination to source) and so on.\n",
    "\n",
    "This explaining capability of a classification(or regression) tree is one of its main benefits. Understanding data is a key factor to build better models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a minimal model using the three main splits\n",
    "\n",
    "So now that we know the main features predicting a network attack, thanks to our classification tree splits, let's use them to build a minimal classification tree with just the main three variables: count, dst_bytes, and flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_labeled_point_minimal(line_split):\n",
    "    # leave out =[41]\n",
    "    clean_line_split = line_split[3:4] + line_split[5:6] + line_split[22:23]\n",
    "    \n",
    "    # convert protocol to numeric categorical variable\n",
    "    try:\n",
    "        clean_line_split[0] = flags.index(clean_line_split[0])\n",
    "        \n",
    "    except:\n",
    "        clean_line_split[0] = len(flags)\n",
    " \n",
    "        \n",
    "    attack = 1.0\n",
    "    if line_split[41] ==\"normal.\":\n",
    "        attack = 0.0\n",
    "        \n",
    "    return LabeledPoint(attack, np.array([float(x) for x in clean_line_split]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [10.0,45076.0,1.0]), LabeledPoint(0.0, [10.0,4528.0,2.0])]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data_minimal = csv_data.map(create_labeled_point_minimal)\n",
    "training_data_minimal.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[LabeledPoint(0.0, [10.0,146.0,1.0])]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_minimal = test_csv_data.map(create_labeled_point_minimal)\n",
    "test_data_minimal.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier trained in 282.922 seconds\n"
     ]
    }
   ],
   "source": [
    "# Build the model\n",
    "t0 = time()\n",
    "tree_model_minimal = DecisionTree.trainClassifier(training_data_minimal, numClasses=2,\n",
    "                                          categoricalFeaturesInfo={0: len(flags)},\n",
    "                                          impurity='gini', maxDepth=8, maxBins=32)\n",
    "tt = time() - t0\n",
    "\n",
    "print \"Classifier trained in {} seconds\".format(round(tt,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions_minimal = tree_model_minimal.predict(test_data_minimal.map(lambda p: p.features))\n",
    "labels_and_preds_minimal = test_data_minimal.map(lambda p: p.label).zip(predictions_minimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction made in 13.915 seconds. Test accuracy is 0.918\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "test_accuracy = labels_and_preds_minimal.filter(lambda (v, p): v == p).count() / float(test_data_minimal.count())\n",
    "tt = time() - t0\n",
    "\n",
    "print \"Prediction made in {} seconds. Test accuracy is {}\".format(round(tt,3), round(test_accuracy,4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have trained a classification tree with just the three most important predictors, in half of the time, and with a not so bad accuracy. In fact, a classification tree is a very good model selection tool!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
